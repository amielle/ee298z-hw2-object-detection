{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 2: Object Detection for EE 298Z\n\nKaggle notebook version for running the code in [this repository](https://github.com/amielle/ee298z-hw2-object-detection). Run the cells in the proper order and ensure that step 1 is followed before running sections 2-4.\n\n## Table of Contents\n1. Setup prerequisites\n2. Run test.py\n3. Run train.py\n4. Plot predictions on sample images","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup prerequisites\n\nInstall libraries not yet present in the Kaggle environment and update torchvision and torch.","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n!pip install torchvision -U\n!pip install torch -U\n!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2022-05-01T13:51:09.157793Z","iopub.execute_input":"2022-05-01T13:51:09.158764Z","iopub.status.idle":"2022-05-01T13:53:37.242993Z","shell.execute_reply.started":"2022-05-01T13:51:09.158644Z","shell.execute_reply":"2022-05-01T13:53:37.242199Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Clone the source repository.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/amielle/ee298z-hw2-object-detection","metadata":{"execution":{"iopub.status.busy":"2022-05-01T13:53:37.244850Z","iopub.execute_input":"2022-05-01T13:53:37.245099Z","iopub.status.idle":"2022-05-01T13:53:38.935513Z","shell.execute_reply.started":"2022-05-01T13:53:37.245063Z","shell.execute_reply":"2022-05-01T13:53:38.934679Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Change the directory to the code repo to access the scripts and modules.","metadata":{}},{"cell_type":"code","source":"import os\nos.chdir(\"./ee298z-hw2-object-detection\")","metadata":{"execution":{"iopub.status.busy":"2022-05-01T13:53:38.937364Z","iopub.execute_input":"2022-05-01T13:53:38.937647Z","iopub.status.idle":"2022-05-01T13:53:38.943271Z","shell.execute_reply.started":"2022-05-01T13:53:38.937607Z","shell.execute_reply":"2022-05-01T13:53:38.942370Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 2. Run test.py\n\nUses the pre-trained model from the repo author to evaluate the model across the test dataset.","metadata":{}},{"cell_type":"code","source":"!python test.py","metadata":{"execution":{"iopub.status.busy":"2022-05-01T13:53:38.945642Z","iopub.execute_input":"2022-05-01T13:53:38.946165Z","iopub.status.idle":"2022-05-01T13:54:07.038746Z","shell.execute_reply.started":"2022-05-01T13:53:38.946127Z","shell.execute_reply":"2022-05-01T13:54:07.037784Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 3. Run train.py\n\nAllows the user to train their own model and displays test metrics at the end. There may be some minor discrepancies from the original pre-trained model due to some differences in the initialization of weights and others.","metadata":{}},{"cell_type":"code","source":"!python train.py","metadata":{"execution":{"iopub.status.busy":"2022-05-01T13:54:07.041754Z","iopub.execute_input":"2022-05-01T13:54:07.042436Z","iopub.status.idle":"2022-05-01T14:26:35.732597Z","shell.execute_reply.started":"2022-05-01T13:54:07.042386Z","shell.execute_reply":"2022-05-01T14:26:35.731714Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 4. Plot predictions on sample images\n\nLoads the original pre-trained model from the repo author. Plots sample bounding boxes and predicted classes (numerical values converted to equivalent text) for sample images on the test dataset.","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch\n\nimport odutils.label_utils as label_utils\nimport odutils.dataprep as dataprep\nimport odutils.odmodel as odmodel\nfrom odutils.config import return_config\n\nimport detection.utils as utils\nfrom detection.engine import train_one_epoch, evaluate\n\nmain_dir = os.getcwd()\n\n# Download dataset and pre-trained model\ndataprep.setup_files(dataset_filename=\"drinks.tar.gz\", \n                     unzip_dataset=True)\n\nconfig = return_config(main_dir)\n\ntest_dict, test_classes = label_utils.build_label_dictionary(\nconfig['test_split'])\ntest_split = odmodel.ImageDataset(test_dict, test_classes, transforms.ToTensor())\n\ntest_loader = DataLoader(test_split,\n                         batch_size=config['batch_size'],\n                         shuffle=False,\n                         num_workers=config['num_workers'],\n                         pin_memory=config['pin_memory'],\n                         collate_fn=utils.collate_fn)\n\n# Change as needed\nmodel_path = f\"{main_dir}/adulay-fasterrcnn_resnet50_fpn-1651304089.3776634.pth\"\nmodel = odmodel.load_model(od_trained_model=model_path)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Plotting part\nfor filename in list(test_dict.keys())[:10]:\n    odmodel.detect_drinks(model, \n                          filename=filename, \n                          detection_threshold=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:26:35.734166Z","iopub.execute_input":"2022-05-01T14:26:35.734457Z","iopub.status.idle":"2022-05-01T14:26:51.080929Z","shell.execute_reply.started":"2022-05-01T14:26:35.734414Z","shell.execute_reply":"2022-05-01T14:26:51.080042Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}