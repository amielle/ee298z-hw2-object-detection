{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 2 Object Detection [Video Generation]\nContains code for the loading the trained model, readings frames from a video file, and applying the object detection model to detect the location of the drinks in the image and the corresponding classes.\n\n**NOTES:** Due to the limitation of live camera video feed in Kaggle notebooks, feeding from a video file (.mp4) was the workaround for the demo submission. A demo file is generated with 640x480 resolution and 30 frames per second.\n\n## 1. Setup and import dependencies\nUpdate torchvision and torch library due to some newly added features not currently available in the preset libraries. Install pycocotools for the vision reference code blocks.","metadata":{}},{"cell_type":"code","source":"!pip install torchvision -U\n!pip install torch -U\n!pip install pycocotools","metadata":{"_uuid":"e1f88fd2-4e1c-464d-af90-8a71d898f006","_cell_guid":"1622d69e-ee0b-4091-9047-b194698fba3e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-30T08:23:15.540434Z","iopub.execute_input":"2022-04-30T08:23:15.540736Z","iopub.status.idle":"2022-04-30T08:25:20.297847Z","shell.execute_reply.started":"2022-04-30T08:23:15.540658Z","shell.execute_reply":"2022-04-30T08:25:20.29705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport label_utils\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:04.006117Z","iopub.execute_input":"2022-04-30T12:54:04.006422Z","iopub.status.idle":"2022-04-30T12:54:05.742303Z","shell.execute_reply.started":"2022-04-30T12:54:04.006340Z","shell.execute_reply":"2022-04-30T12:54:05.741575Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\ndef create_model(num_classes):\n    # load Faster RCNN pre-trained model\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n    \n    # get the number of input features \n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # define a new head for the detector with required number of classes\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:15.699054Z","iopub.execute_input":"2022-04-30T12:54:15.699300Z","iopub.status.idle":"2022-04-30T12:54:15.706002Z","shell.execute_reply.started":"2022-04-30T12:54:15.699273Z","shell.execute_reply":"2022-04-30T12:54:15.704273Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"od_trained_model = \"../input/ee298z-hw2-od-weights/adulay-fasterrcnn_resnet50_fpn-1651304089.3776634.pth\"\nnum_classes = len(label_utils.params[\"classes\"])\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = create_model(num_classes=num_classes).to(device)\nmodel.load_state_dict(torch.load(\n    od_trained_model, map_location=device\n))\nmodel.eval() # set for inference and not training mode","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:54:20.379350Z","iopub.execute_input":"2022-04-30T12:54:20.379608Z","iopub.status.idle":"2022-04-30T12:54:37.442315Z","shell.execute_reply.started":"2022-04-30T12:54:20.379580Z","shell.execute_reply":"2022-04-30T12:54:37.441633Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import sys\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef preprocess_frame(image):\n    # BGR to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    # make the pixel range between 0 and 1\n    image /= 255.0\n    # bring color channels to front\n    image = np.transpose(image, (2, 0, 1)).astype(float)\n    # convert to tensor\n    image = torch.tensor(image, dtype=torch.float).cuda()\n    # add batch dimension\n    image = torch.unsqueeze(image, 0)   \n    return image\n\ndef detect_drinks(filename, detection_threshold=0.8, read_from_file=True, image=None, to_plot=True):\n    # lowest value found at around ~0.8, adjust to lower value to 'capture more'/higher allowance\n    # default threshold set to 0.8 since 0.75 captures other objects in the background as drinks\n    # setting to a higher value (e.g. 0.9) lowers those cases\n\n    if read_from_file:\n        image = cv2.imread(filename)\n    orig_image = image.copy()\n    image = preprocess_frame(image)\n\n    outputs = model(image)\n\n    # load all detection to CPU for further operations\n    outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n    # carry further only if there are detected boxes\n    if len(outputs[0]['boxes']) != 0:\n        boxes = outputs[0]['boxes'].data.numpy()\n        scores = outputs[0]['scores'].data.numpy()\n        # filter out boxes according to `detection_threshold`\n\n        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n        draw_boxes = boxes.copy()\n        # get all the predicited class names\n        pred_classes = [label_utils.params[\"classes\"][i] for i in outputs[0]['labels'].cpu().numpy()]\n\n        # draw the bounding boxes and write the class name on top of it\n        for j, box in enumerate(draw_boxes):\n            cv2.rectangle(orig_image,\n                        (int(box[0]), int(box[1])),\n                        (int(box[2]), int(box[3])),\n                        (0, 0, 255), 2)\n            cv2.putText(orig_image, pred_classes[j], \n                        (int(box[0]), int(box[1]-5)),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), \n                        2, lineType=cv2.LINE_AA)\n\n        if to_plot:\n            imgplot = plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n            plt.show()\n\n    return orig_image","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:41.788457Z","iopub.execute_input":"2022-04-30T12:55:41.788719Z","iopub.status.idle":"2022-04-30T12:55:41.801605Z","shell.execute_reply.started":"2022-04-30T12:55:41.788691Z","shell.execute_reply":"2022-04-30T12:55:41.800966Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"vid = cv2.VideoCapture('../input/ee298z-hw2-od-vids/WIN_20220430_16_01_02_Pro.mp4')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:57.206461Z","iopub.execute_input":"2022-04-30T12:55:57.207124Z","iopub.status.idle":"2022-04-30T12:55:57.471433Z","shell.execute_reply.started":"2022-04-30T12:55:57.207086Z","shell.execute_reply":"2022-04-30T12:55:57.470677Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import time\n\nout_vid = cv2.VideoWriter(f'demo-{time.time()}.mp4',\n                        cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n                        30,\n                        (640,480), \n                        isColor=True)\n\nwhile(vid.isOpened()):\n    ret, frame = vid.read()\n    if ret == True:\n        detected_frame = detect_drinks(None, \n                      detection_threshold=0.9, \n                      read_from_file=False, \n                      image=frame,\n                      to_plot=False)\n        detected_frame = cv2.resize(detected_frame,(640,480),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n        out_vid.write(detected_frame)\n    else:\n        break\n\nvid.release()\nout_vid.release()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:55:58.456511Z","iopub.execute_input":"2022-04-30T12:55:58.457053Z","iopub.status.idle":"2022-04-30T12:58:37.119417Z","shell.execute_reply.started":"2022-04-30T12:55:58.457012Z","shell.execute_reply":"2022-04-30T12:58:37.118684Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Optional: Run the following code block to generate a download link for the demo video for cases when output panel in Kaggle is slightly unresponsive.","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\nos.chdir(r'/kaggle/working')\n\n# Note: change the time portion of the filename during the actual runtime\nFileLink(r\"./demo-1651323358.4610178.mp4\")","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:59:28.730590Z","iopub.execute_input":"2022-04-30T12:59:28.730860Z","iopub.status.idle":"2022-04-30T12:59:28.739243Z","shell.execute_reply.started":"2022-04-30T12:59:28.730829Z","shell.execute_reply":"2022-04-30T12:59:28.738389Z"},"trusted":true},"execution_count":7,"outputs":[]}]}